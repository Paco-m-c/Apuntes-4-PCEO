\documentclass[openany]{book}
\usepackage[utf8]{inputenc}
\usepackage{verbatim}
\usepackage[hypertexnames=false]{hyperref}
\usepackage{amstext} 
\usepackage{array}   
\newcolumntype{C}{>{$}c<{$}} 


\input{structure}
\usepackage{geometry}
\geometry{
    top=3cm,
    bottom=3cm,
    left=3cm,
    right=3cm,
    headheight=14pt, 
    footskip=1.4cm,
    headsep=10pt,
}
\usepackage{graphicx}
\title{Ejercicios MNED}
\author{Paco Mora Caselles}
\date{\today}

\begin{document}

    \maketitle
    \chapter{Tema 1}


    \begin{exercise}
        $$ A_1 = \begin{pmatrix} 0.5 & 1 \\ -1 & 0.5 \end{pmatrix} \to \sigma(A) = \{0.5+i,0.5-i\} $$
        $ x,y $ son combinaciones lineales de $ e^{(0.5\pm i)t} $ es decir de $ \{e^{0.5t}e^{i},e^{0.5}e^{-i}\} $
    \end{exercise}

    \setcounter{ex}{4}
    \begin{exercise}
        $$ 
        \left\{
        \begin{array}{l}
            x'''(t) = \cos(x(t))+ \sin(x'(t)) - e^{x''(t)}+t^2\\
            x(0) = 3\\
            x'(0) = 7\\
            x''(0) = 13
        \end{array}
        \right.
        $$
        Consideramos 
        $$ 
        \left\{
        \begin{array}{l}
            x(t)\\
            u(t) = x'(t)\\
            v(t) = x''(t)
        \end{array}
        \right.
        $$
        Entonces la ecuación queda:
        $$ v'(t) = (x'''(t)) = (\cos(x(t)))+\sin(u(t))-e^{v(t)}+t^2 $$
        $$ \begin{pmatrix} x(t)\\u(t)\\v(t) \end{pmatrix} = \begin{pmatrix} 3 \\ 7 \\13 \end{pmatrix}  $$
        En versión matricial:
        $$ X(t) = \begin{pmatrix} x(t)\\u(t)\\v(t) \end{pmatrix}  $$
        $$ \dfrac{d}{dt} X(t) = F(t,X(t)) = \begin{pmatrix} u \\ v \\ \cos(x)+\sin(u)-e^{v}+t^2 \end{pmatrix}  $$
    \end{exercise}

    \setcounter{ex}{8}

    \begin{exercise}
        $$ e^{at}(y'+ay) = e^{at}y' + ae^{at}y = \dfrac{d}{/dt}(e^{at}y(t)) $$
        $$ e^{\int_{0}^{t}a(s)ds}\left(y'(t)-a(t)y(t)) = e^{\int_{0}^{t}a(s)ds}  y'(t)+a(t)e^{\int_{0}^{t}a(s)ds}y(t) \right) \dfrac{d}{dt}(e^{\int_{0}^{t}a(s)ds}y(t)) $$
        $$ \int_{0}^{t}\dfrac{d}{dt}(e^{at}y(t)) = e^{at}y(t)|_{t=0} ^{(t = t)} $$
        $$ \dfrac{d}{dt}(e^{at}y(t)) = d e^{at-bt} $$
        % No entiendo ni media de esto
    \end{exercise}

    \chapter{Tema 2}

    

    \setcounter{ex}{7}
    \begin{exercise}
        % \textbf{Ejercicio 8}\\
        a)
        $$ y_n = \dfrac{1-h}{1+(n-1)h}\ n = 0,..,N = \dfrac{1}{h}$$
        b)\\
        Utilizando que es una ecuación de variables separables, llegamos a:
        $$ y(t) = \dfrac{1}{1+t}  $$
        %no se que hace yo copio
        Dado $ t_{*}= nh  $ fijo, calculamos el límite estacionario:
        $$ \lim_{h \to 0\ n\to +\infty\ hn = t_{*}}y_{n}^{h}  = \lim \dfrac{1-h}{1+nh-h} = \lim \dfrac{1-h}{1+t_{*}-h} = \dfrac{1}{1+t_{*}} = y(t_{*})$$
        Es decir la solución exacta que hemos calculado.\\
        c)\\
        El resultado es:
        $$ y(t_{*})-y_{n}^h = \dfrac{-t_{*}h}{1+t_{*}^2+2t_{*}-h-ht_{*}} = O(h)_{h \to 0}$$
        con $ hn = t_{*} $.\\
        Que el error sea una $ O(h) $ significa que $ |y(t_{*}-y_{n}^h| \leq_{h\to 0} kh $
        Con $ k $ independiente de $ h $.\\
        Comprobaremos que el error sea una $ O(h) $:
        $$ |y(t_{*}-y_n^h| = h \dfrac{t_{*}}{|1+t_{*}^2+2t_{*}-h-ht_{*}|} $$
        Teniendo:
        $$ \dfrac{t_{*}}{1+t_{*}^2+2t_{*}-h-ht_{*}}\sim _{h\to 0} \dfrac{t_{*}}{1+t_{*}^2+2t_{*}} \leq \dfrac{1}{1} = 1 $$ 
        Luego el error lo podemos acotar por $ hk $ con $ k = 1 $ cuando $ h \to 0 $.\\
        
        Comprobaremos la optimalidad de esta cota.
        $$ y(t_{*})-y_{n}^h = \dfrac{-t_{*}h}{1+t_{*}^2+2t_{*}-h-ht_{*}} \leq ? k h^2 $$
        $$ \dfrac{1}{h^2} y(t_{*})-y_{n}^h = \dfrac{-t_{*}h}{1+t_{*}^2+2t_{*}-h-ht_{*}} \to_{h\to 0} \infty $$
        Luego el error es mayor o igual que $ h $ y menor que $ h^2 $.
        

    \end{exercise}
    

    \setcounter{ex}{5}
    \begin{exercise}
        $$ \left\{
        \begin{array}{l}
            y'(t) = t\\
            y(0) = 0
        \end{array}
        \right. $$
        Con solución exacta $ y(t) = \dfrac{t^2}{2} $
        El método de Euler explícito queda:
        $$ \left\{
        \begin{array}{l}
            y_0 = 0\\
            y_{n+1} = y_n + hf(t_n,g_n) = y_n +ht_n 
        \end{array}
        \right. $$

        Entonces:
        $$ y_0 =0\hspace{5mm}y_1 = y_0 +ht_0 = 0+0h = 0 $$
        $$ y_2 = 0 + hh = h^2\hspace{5mm}y_3 = h^2+2h^2 = 3h^2 $$
        $$ y_4 = (1+2+3) = 6h^2 \hspace{5mm} y_5 = (1+2+3+4)h^2 = 10h^2  $$
        En general:
        $$ y_n = (1+2+...+n-1)h^2  = \dfrac{(n-1)n}{2}h^2 = \dfrac{n^2-n}{2}h^2 = \dfrac{1}{2}n^2h^2-\dfrac{1}{2}nhh = \dfrac{1}{2}t_{*}^2-\dfrac{1}{2}t_{*}h \to \dfrac{1}{2}t_{*}^2$$
        Con lo que tenemos un error del orden de $ O(h) $
        
        \begin{flushright}
            \textbf{Variación del ejercicio}
        \end{flushright}
        $$ \left\{
        \begin{array}{l}
            y'(t) = 1\\
            y(0) = 0
        \end{array}
        \right. $$
        Con solución exacta $ y(t) = t $
        El método de Euler explícito queda:
        $$ \left\{
        \begin{array}{l}
            y_0 = 0\\
            y_{n+1} = y_n +h f(t_n,y_n) = y_n+h
        \end{array}
        \right. $$
        Con lo que:
        $$ y_0 = 0 \hspace{5mm} y_1 = h \hspace{5mm} y_2 = 2h\ ... $$
        $$ y_n = nh = t_{*} = y(t_{*}) $$
        Con lo que hemos obtenido la solución exacta, $ \forall t_{*} = nh\ y(t_{*}) - y_n^{h} = 0 $.
        ¿Por qué no hay error en el método de Euler en este caso? Porque la segunda derivada de la solución exacta, $ y'' \equiv 0 $ y porque hemos tomado un $ t_0 $ que forma parte de la solución.

        Si en vez de tomar 0 tomamos $ t_0 = \varepsilon $:
        $$ y_0 = \varepsilon \hspace{5mm} y_1 = \varepsilon +h \hspace{5mm} y_2 = \varepsilon +2h $$
        $$ y_n = \varepsilon +nh $$
        En este caso al no tomar un $ y_0  $ exacto el error se desvía por $ \varepsilon $

    \end{exercise}

    \setcounter{ex}{2}
    $$ (1+hL)^{n} \sim? e ^{Lt} $$
    con $ t = nh $
    O equivalentemente, que $ \lim_{t = nh} (1+hL)^{n} = e^{Lt}$
    $$ (1+hL)^{n} = e^{n \log(1+hL)} = e^{hn \dfrac{\log(1+hL)}{h}} \to e^{Lt} $$
    
    \textbf{c)}\\
    $$ (1+O(h^{p+1}))^{n} = exp(n \log(1+O(h ^{p+1}))) = exp(hn \dfrac{\log(1+O(h^{p+1}))}{n}) = e ^{t \dfrac{\log(1+O(h^{p+1}))}{n}} = ...$$
    Hacemos el desarrollo de Taylor en el exponente y nos queda $  = exp(t(O(h^{p})+...)) $
    
    \setcounter{ex}{9}
    
    \begin{exercise}
        Calculamos primero la solución exacta aunque no nos lo pida el ejercicio.
        $$ \left\{
        \begin{array}{l}
            y'(t) = \alpha y(t)+\beta\\
            y(0) = y_0
        \end{array}
        \right. $$
        $$ y' = -\alpha y = \beta $$
        $$ e^{-\alpha t}- \alpha e ^{-\alpha t} y = e ^{-\alpha t}y $$
        $$  \dfrac{d}{dt}(e^{-\alpha t }) y = e^{-\alpha t}\beta  $$
        $$ e^{-\alpha t}y -y_0 = \int_{0}^{t}e^{-\alpha s} \beta ds $$
        % $$ e^{-\alpha t}-y_0 = \dfrac{e^{-\alpha t}-1}{-\alpha}\beta $$
        $$ y(t) = e^{-\alpha t} y_0 - \dfrac{\beta}{\alpha}(1-e^{\alpha t}) $$
        Hacemos ahora Euler explícito:
        $$ \left\{
        \begin{array}{ll}
            u_{n+1} = y_n +h f(t_n,u_n) & n=0,...,\dfrac{N}{T}-1\\
            u_0 = A & \text{podemos asumir $ A = y_0 $}
        \end{array}
        \right. $$
        Recordemos que cada $ u_n $ es una aproximación a $ y(t_n) $.
        También podemos usar $ y_n $ como aproximación a $ y(t_n) $\\
        Es importante saber que $ y_n \ne y(t_n) $.\\
        En nuestro caso, $ f(t,y) = \alpha y +\beta $, luego $ u_{n+1} = u_n+h(\alpha y_n+\beta) $\\
        Tenemos entonces dos opciones:
        \begin{itemize}
            \item $ u_1=u_0+h(\alpha u_0+\beta) $\\
            $ u_2 =  u_1h \alpha( u_1+\beta) = u_1+h \alpha(u_0+h(\alpha u_0+\beta)+\beta) = $\\$ = u_1 + u_0 (h \alpha(h \alpha)^2+\beta (h^2alfa h \alpha)) = u_1 +h \alpha (1+h \alpha ) u_0+h \alpha (h+1) \beta$
            \item $ u_{n+1} = (1+h \alpha ) u_n+\beta h $, lo que nos queda:
                $ u_1 = (1+h \alpha ) u_0 + \beta h $\\ $ u_2 = (1+h \alpha )u_1+\beta h (1+h \alpha )u_0+ \beta h(1+(1+h \alpha))\\ u_3 = (1+h \alpha )u_2 + \beta h = (1+h \alpha) ((1+h \alpha)^2 u_0 + \beta h (1+(1+h \alpha))) + \beta h = (1+h \alpha) ^3 + \beta h(1(1+h \alpha )+ (1+h \alpha )^2) $\\
                $ u_n = (1+ h \alpha) ^{n} u_0 + \beta h (1+(1+h \alpha)+...+(1+h \alpha )^{n-1}) $\\
                $   = (1+h \alpha ) ^{n}u_0+ \dfrac{\beta}{\alpha}[(1+h \alpha )^{n}-1] $
        \end{itemize}
        
        Podemos observar que la convergencia del segundo método es mejor.

        Vamos a comprobar que $ u_n \to_{h \to 0,\ n \to +\infty,\ hn = t} y(t) $ cuando $ t = hn $ fijo.

        Sabemos que $ \lim_{x \to +\infty} \left(1+\dfrac{a}{x}\right) = e^{a} $. Entonces, $ (1+h \alpha)^{n} (1+\dfrac{h n}{n}\alpha) \to e ^{t \alpha}$, el valor que toma la solución exacta en el punto $ t_0 $.

        Calculemos ahora el error, sabemos que:
        $$ \int_{}^{} \dfrac{1}{1+x} = 1-x+x+x ^2-x^3 +... $$
        $$ \log{1+x} = x-\dfrac{x^2}{2} + \dfrac{x^3}{3}+... \hspace{5mm} \text{Desarrollo de Taylor de $ \log{1+x} $ alrededor de $ x=0 $ } $$
        
        El desarrollo de $ \dfrac{\log{(1+x)}}{x} = 1-\dfrac{x}{2}+O(x^2) $ con $ |x| \to 0 $

        Tomando entonces una $ x $ adecuada:

        $$ (1+h \alpha) ^{n} = e ^{n \log{(1+h \alpha)}} = e ^{n h \alpha \dfrac{\log{(1+h \alpha)}}{h \alpha}} = e ^{t \alpha (1- \dfrac{h \alpha}{2}+O(h^2))} = e ^{t \alpha }e^{-\dfrac{h \alpha ^2 t}{2}+ O(h^2)}$$

        Entonces, $ (1+h \alpha )^{n} = -e^{t \alpha} = e^{t \alpha} e^{...}-e^{t \alpha} = e^{t \alpha}(e ^{...}-1) = e ^{t \alpha }(... + \dfrac{[...]^2}{2!}+...) = $\\
        $ e ^{\alpha t} (-\dfrac{h \alpha ^2 t}{2}) + O(h^2) $

        Hemos llegado a:
        $$ (1+h \alpha) ^{n} - e^{t \alpha} = -\dfrac{h \alpha ^2 t}{2} e ^{\alpha t} + O(h ^2) $$
        
        Y el error es:
        $$ u_n-y_n = ((1+ h \alpha) ^{n}- e ^{ \alpha t})u_0 + \dfrac{\beta}{\alpha}((1+h \alpha)^{n}- e ^{\alpha t}) = -\dfrac{h \alpha ^2 t}{2}(u_0+ \dfrac{\beta}{\alpha}) e ^{\alpha t}+ O(h ^2)\hspace{5mm}h \to 0$$



        

    \end{exercise}

    \setcounter{ex}{11}

    \begin{exercise}
        Comprobamos el orden de Euler explícito del problema: 
        $$ y'(x) = \dfrac{1}{\sqrt{1-x}} \hspace{5mm} y(0) = 0 $$

        Observamos que la solución es $ y(x) = -\dfrac{(1-x)^{1/2}}{\dfrac{1}{2}} = 2 \sqrt{1-x} $

        Tenemos un problema en 1 ya que la derivada no está acotada en ese punto.

        % Observamos que $ f_{y} = 0  $ y $ f_{x} = \dfrac{1}{2}(1-x)^{-3/2} $, vamos a calcular los primeros términos de la recurrencia tomando $ x_n \in [0,1] $:

        % $$ y_1 = 0 + h(1-x_n)^{-\dfrac{1}{2}} = h$$
        % $$  y_2 = h+h(1-x_1)^{-\dfrac{1}{2}} $$
        
        Vemos la expresión del error local:
        $$ \ell(t;h) = \dfrac{h^2}{2} y''(t) $$
        $$ \ell(x;h) = \dfrac{h^2}{2} y''(x) $$
        
        Vemos que $ y''(x) = \dfrac{1}{2}(1-x)^{-3/2} $. En el caso de que $ x $ sea de la forma $ x = 1-h $ tendremos que $ \ell(1-h;h) = \dfrac{h^2}{4} \dfrac{1}{h^{3/2}} = \dfrac{1}{4} h ^{1/2}$
        Con lo que el error global no convergerá (tiene orden $ \dfrac{1}{2}-1 $).


    \end{exercise}

    \begin{exercise}
        $ n\geq N-1\\ 0 < \theta < 1,\ h=\dfrac{T}{N} $
        $$ \left\{
        \begin{array}{l}
            y_{n+1} = y_n+h f(t_n+ \theta h, y_n+ \theta f(t_n,y_n) )\\
            y_0\ dado
        \end{array}
        \right. $$

        Los pasos ahora son:
        \begin{enumerate}
            \item Obtenemos $ f(t_n,y_n) $
            \item Avanzamos desde $ (t_n,y_n) $ con pendiente $ f(t_n,y_n) $ hasta el punto $ t_{n+\theta} = t_n+ \theta h $ y obtenemos la abscisa $ y_{n+\theta} = y_n+\theta hf(t_n,y_n) $
            \item Sobre el punto $ (t_{n+\theta},y_{n+\theta}) $ obtenemos una nueva pendiente $ f(t_{n+\theta},y_{n+\theta}) $
            \item Aquí disponemos ya de dos pendientes, lo ideal es tomar $ k = b_1k_1+b_2k_2  $ con $ b_1+b_2 = 1 $ promedio y entonces avanzar desde $ t_n $ a $ t_{n+1} $ con esta pendiente:
                $$ y_{n+1} = y_n + hk \hspace{5mm} \text{con } k = b_1k_1+b_2+k_2 $$
            \item en el caso de este ejercicio es $ b_1 = 0,\ b_2 = 1 $ 


        \end{enumerate}
    
    \end{exercise}


    \setcounter{ex}{15}

    \begin{exercise}
        $$ \left\{
        \begin{array}{l}
            x''(t) = f(t,x(t),x'(t)) \\
            x(0) = x_0\\
            x'(0) = v_0
        \end{array}
        \right. $$
        Usando el método
        $$ \left\{
        \begin{array}{l}
            y_{n+1} = y_n+hz_n+\dfrac{h^2}{2}f_n\\
            z_{n+1} = z_n+hf_n\\
            y_0=x_0\\
            z_0=v_0
        \end{array}
        \right. $$
        Se aproxima entonces $ y_n \sim x(t_n) $ y $ z_n \sim x'(t_n) $.
        
        Tomamos $ y(t) = x(t) $ y $ z(t) $. El sistema se escribe entonces como:
        $$ \dfrac{d}{dt} \binom{y(t)}{z(t)} = \left[ \begin{matrix}
            z(t) \\ f(t,y(t),z(t))
        \end{matrix} \right] $$
        con $ y(0) = x_0,\ z(0) = v_0 $.

        Si usamos la notación $ X = \binom{y(t)}{z(t)} $ tenemos:
        $$ \left\{
        \begin{array}{l}
            \dfrac{d}{dt}X(t) = F(t,X(t))\\
            X(0) = X_0 = \binom{x_0}{v_0}
        \end{array}
        \right. $$
        con
        $$ F(t,X(t)) = \binom{X_2(t)}{f(t,X_1(t),X_2(t))} $$

        Si usamos, por ejemplo, Euler explícito sería:
        $$ \left\{
        \begin{array}{l}
            X_{n+1} = X_n + h F(t_n,X_n) \to \left\{
            \begin{array}{l}
                y_{n+1} = y_n+h z_n\\
                z_{n+1} = z_n+h\underbrace{f(t_n,y_n,z_n)}_{f_n}
            \end{array}
            \right.\\
            X_0\ dado
        \end{array}
        \right. $$

        En el caso de nuestro ejercicio, la parte de $ z_{n+1} $ es igual a Euler explícito, mientras que $ y_{n+1} $ sí cambia. Tendremos un error de segundo orden en $ y $ uno de primer orden en $ z $

        % Comprobamos el orden de $ y $ viendo la relación que tiene su expresión con el desarrollo de Taylor:
        % $$ y_{n+1} = y_n+hz_n+\dfrac{h^2}{2}f(t_n,z_n,y_n)  \to \ell(t;h) = O(h^3) $$
        % (recordemos que el orden del método es una unidad menor que el del error local, $ \ell $)

        $$ \ell(t;h) = \binom{\ell_{y}(t;h)}{\ell_{z}(t;h)}  $$
        
        Para calcular $ \ell $ suponemos la hipótesis de localización $ z_n = z(t),\ y_n = y(t),\  z(t) = y'(t)$:
        $$ \ell_{y}(t;h) = y(t+h)-y(t)-hz(t) - \dfrac{h^2}{2}f(t,y(t),z(t)) = y(t+h)-y(t)-hy'(t)-\dfrac{h^2}{2}y''(t) = $$
        $$  = \dfrac{h^3}{3!}y'''(\xi) $$
        Y utilizando el desarrollo de la primera derivada:
        $$ \ell_{z}(t;h) = z(t+h)-z(t)-hf(t,y(t),z(t)) = y'(t+h)-y'(t)-hy''(t) = \dfrac{h^2}{2}y'''(\eta) $$

        Por tanto el orden del error local del método será el mínimo entre estos dos:
        $$ ||\ell||_{\infty} = \max \{|\ell_{y}|,|\ell_{z}|\} = O(h^2)  $$
        Y el método será de orden 1 (uno menor que su error local).

        Vemos ahora la estabilidad del método, recordemos que $ ||\ell||_{1} = \dfrac{h^3}{6}||y'''||_{\infty} + \dfrac{h^2}{2} ||y''||_{\infty} $:

        $$ \left\{
        \begin{array}{l}
            y_{n+1} = y_n +hz_n +\dfrac{h^2}{2}f_n\\
            z_{n+1} = z_n+hf_n
        \end{array}
        \right. $$

        $$ \left\{
            \begin{array}{l}
                \tilde{y}_{n+1} = \tilde{y}n +h\tilde{z}_n +\dfrac{h^2}{2}f_n\\
                \tilde{z}_{n+1} = \tilde{z}_n+hf_n
            \end{array}
            \right. $$
        
            $$ y_{n+1}-\widetilde{y}_{n+1} = y_n-\widetilde{y}_{n} + h(z_n-\widetilde{z}_{n}) + \dfrac{h^2}{2}(f_n-\widetilde{f}_{n})$$
            $$ z_{n+1}-\widetilde{z}_{n+1} = z_n-\widetilde{z}_{n}h(f_n-\widetilde{f}_{n}) $$

            Suponemos que:
            $$ |f(t,y,z)-f(t,\widetilde{y},\widetilde{z}| \leq L(|y-\widetilde{y}|+ |z-\widetilde{z}|) $$
            equivale a tener $ \dfrac{\partial f}{\partial y}, \dfrac{\partial f}{\partial z} $ acotadas por $ L $.

            Entonces:
            $$ |y_{n+1}-\widetilde{y}_{n+1}| \leq |y_n-\widetilde{y}_{n}| + h|z_n-\widetilde{z}_{n}| + \dfrac{h^2}{2}L(|y_n-\widetilde{y}_{n}| + |z_n-\widetilde{z}_{n}|) $$
            $$ \leq (1+\dfrac{h^2}{2}L) |y_n-\widetilde{y}_{n}| +h(1+\dfrac{h}{2}L)|z_n-\widetilde{z}_{n}|  $$
            $$ |z_{n+1}-\widetilde{z}_{n+1}| \leq |z_n-\widetilde{z}_{n}| +hL(|y_n-\widetilde{y}_{n}|+|z_n-\widetilde{z}_{n}|) \leq (1+hL) |z_n-\widetilde{z}_{n}| + hL|y_n-\widetilde{y}_{n}| $$

            Entonces tendremos que:
            $$ \underbrace{|y_{n+1}-\widetilde{y}_{n+1}|+|z_{n+1}-\widetilde{z}_{n+1}|}_{\tilde{\theta}_{n+1}} \leq (1+hL+\dfrac{h^2}{2}L) |y_n-\widetilde{y}_{n}| + (1+h+\dfrac{h}{2}L+hL) |z_n-\widetilde{z}_{n}| $$
            $$ \tilde{\theta}_{n+1} \leq (1+h\Lambda) \tilde{\theta}_n\ (\text{con $ \Lambda = O(1) $ y $ \Lambda = \max\{1+\dfrac{h}{2}L,\dfrac{h}{2}L\} $}) $$

            Iterando llegamos a $ \tilde{\theta}_{n} \leq (1+h\Lambda)^{n}\tilde{\theta}_{0} \leq e^{t_n \Lambda}\tilde{\theta}_{0} $

        Vamos ahora al error global del método:
        $$ \theta_{n} = |y(t_n)-y_n| + |z(t_n)-z_n| $$
        
        Usamos:
        $$ \left\{
        \begin{array}{l}
            \widetilde{y}_{n} = y(t_n)+hz(t_n)+hf(t_n,y(t_n),z(t_n)) \\
            \widetilde{z}_{n} = z(t_n) + hf(t_n,y(t_n),z(t_n))
        \end{array}
        \right. $$

        Tendremos entonces:
        $$ \theta_{n} = |y(t_n)+\widetilde{y}_{n}+\widetilde{y}_{n}-y_n| + |z(t_n)-\widetilde{z}_{n}+\widetilde{z}_{n}+z_n| \leq |y(t_n)-\widetilde{y}_{n}|+|z(t_n)-\widetilde{z}_{n}| + |\widetilde{y}_{n}-y_n| + |\widetilde{z}_{n}-z_n| \leq $$
        $$\leq\underbrace{\dfrac{h^3}{6}||y'''||_{\infty}+ \dfrac{h^2}{2}||y'''||_{\infty}}_{\ell(h)}  + (1+h\Lambda)\theta_{n+1}$$
        $$ \theta_{n} \leq \ell(h) + (1+h\Lambda)\theta_{n-1} $$
        Iterando:
        $$ \theta_{n} \leq (1+h\Lambda)^{n}\theta_{0} + \dfrac{(1+h\Lambda)^{n}-1}{1+h\Lambda -1}\ell(h) \leq e^{T\Lambda}\theta_{0}+ \dfrac{e^{T\Lambda}-1}{\Lambda} \dfrac{\ell(h)}{h} = O(1) $$

    \end{exercise}


    \chapter{Tema 4}

    \setcounter{ex}{3}

    \begin{exercise}
        $$ 
        \begin{array}{c|ccc}
            0 & 0 & 0 & 0\\
            1 & 1 & 0 & 0\\
            1 & \dfrac{1}{2} & \dfrac{1}{2} & 0 \\\\
            \hline\\
            & \dfrac{3}{6} & \dfrac{1}{6} & \dfrac{2}{6}
        \end{array}
        $$

        Las condiciones para obtener un orden 3 son:
        \begin{enumerate}
            \item $ b_1+b_2+b_3 = 1 $ (lo tenemos) 
            \item $ b_2c_2+b_3c_3 = \dfrac{1}{2} $ (también se cumple)
            \item $ b_2+c_2^2+b_3c_3^2 = \dfrac{1}{3} $
        \end{enumerate}
        
        La última condición no se cumple, luego el método no es de orden $ 3 $, $ \ell(h) = O(h^{p+1}) $ para $ p \leq 2 $ (recordemos que el orden del error local es uno más que el método).

        Si usamos $ y'=y $ puede que la solución sea más precisa, pero esto no va a ocurrir en general. Con lo que no contradecimos con lo que hemos dicho para el orden del método:

        $$ f(t,y)=y \implies \left\{
        \begin{array}{l}
            k_1 = y_n\\
            k_2 = y_n+hy_n = (1+h)y_n\\
            k_3 = y_n + \dfrac{h}{2}(y_n+hy_n) = y_n+hy_n+\dfrac{h^2}{2}y_n = y_n\left(1+h+\dfrac{h^2}{2}\right)
        \end{array}
        \right.$$

        Entonces $ y_{n+1} = y_n+h \left( \dfrac{3}{6}y_n + \dfrac{1}{6}(1+h)y_n + \dfrac{2}{6}\left(1+h+\dfrac{h^2}{2}\right) y_n \right) = y_n \left( 1+h+\dfrac{h^2}{2}+\dfrac{h^3}{6} \right) $.

        Con lo que $ y_n = T_{3}(h)^{n} $ donde $ T_{3}(h) = 1+h+\dfrac{h^2}{2}+\dfrac{h^3}{3} $ y $ e^{h} = T_3(h) + O(h^{4}) $ y $ T_3(h) = e^{h}(1+O(h^{4})) $ Entonces:

        $$ T_{3}(h)^{n} =  e^{t_n} (1+O(h^{4}))^{n} = e^{t_n}(1+O(h^{3})) \implies y_n - e^{t_n} = O(h^3)$$

    \end{exercise}

    \setcounter{ex}{9}

    \begin{exercise}
        $$ y_{n+1} = y_n+h(\dfrac{1}{4}k_1+\dfrac{3}{4}k_2) $$
        Con:
        $$ \left\{
        \begin{array}{l}
            k_1 = f(t_n,y_n)\\
            k_2 = f(t+\dfrac{2}{3}h,y_n+\dfrac{2}{3}hf(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1))
        \end{array}
        \right. $$
        Podemos observar que la expresión anidada en $ k_2 $ parece una nueva $ k_i $, cambiamos nuestras $ k's $ para que el problema sea más intuitivo:
        $$ 
        \left\{
        \begin{array}{l}
            k_1 = f(t_n,y_n)\\
            k_2 = f(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1)\\
            k_3 = f(t_n+\dfrac{2}{3}h,y_n+\dfrac{2}{3}hk_2)\\
            y_{n+1} = y_n+h(\dfrac{1}{4}k_1+\dfrac{3}{4}k_3)
        \end{array}
        \right.
        $$

        \textbf{b)}

        El tablero de Butcher es:

        $$ 
        \begin{array}{c|ccc}
            0 & 0 & 0 & 0 \\
            \dfrac{1}{3} & \dfrac{1}{3} & 0 & 0\\ \\
            \dfrac{2}{3} & 0 & \dfrac{2}{3} & 0 \\ \\
            \hline \\
            & \dfrac{1}{4} & 0 & \dfrac{3}{4}

        \end{array}
        $$

        \textbf{c)}

        Comprobamos el orden:
        \begin{enumerate}
            \item $ b_1+b_2+b_3 = 1 $ (Se cumple)
            \item $ b_2c_2+b_3c_3 = \dfrac{1}{2} $ (Se cumple)
            \item $ b_2c_2^2+b_3c_3^2 = \dfrac{1}{3} $ (Se cumple)
            \item $ b_3c_2c_3 = \dfrac{1}{6} $ (Se cumple)
        \end{enumerate}

        Por tanto, el método es de orden máximo y en nuestro caso, es de orden 3.

        \textbf{a)}
        $$ y_{n+1} = y_n+h \Phi_{f}(t_n,y_n;h)\ \text{donde } \Phi_{f}(t_n,y_n;h) = \dfrac{1}{4}k_1+\dfrac{3}{4}k_3 $$
        $$ k_1 = f(t_n,y_n) \implies \text{$ k_1 $ es Lips con respecto al segundo argumento} $$
        $$ k_2 = f(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1) $$
        $$ k_2(y_n) = f(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1(y_n)) $$
        $$ k_2(z_n) = f(t_n+\dfrac{1}{3}h,z_n+\dfrac{1}{3}hk_1(z_n)) $$
        $$ |k_2(y_n)- k_2(z_n) | \leq L_{f}|y_n+\dfrac{1}{3}hk_1(y_n) - (z_n+\dfrac{1}{3}hk_1(z_n))| \leq L_{f}(|y_n-z_n|+\dfrac{1}{3}h(k_1(y_n)-k_1(z_n)))\leq$$
        $$ \leq L_{f}(|y_n-z_n| + \dfrac{1}{3}h |y_n-z_n|L_{f}) = (L_{f}+\dfrac{1}{3}hL_{f}^2) |y_n-z_n| = L_{f}' |y_n-z_n| $$

        $$ |k_3(y_n) - k_3(z_n)| \leq L_{f}(|y_n-z_n|  \dfrac{2}{3}h|k_2(y_n)-k_2(z_n)|) \leq L_{f}(1+\dfrac{2}{3}hL_{f}L_{f}') |y_n-z_n| $$

        En general:
        $$ y_{n+1} = y_n + h \Phi_{f}(t_n,y_n;h) $$
        $$ z_{n+1} = z_n + h \Phi_{f}(t_n,z_n;h) $$
        $$ |y_n-z_n| \leq (1+h \Lambda _{\Phi_{f}}) |y_n-z_n| $$
        con $ \Lambda_{f} = O(1) $ con lo que:
        $$ |y_n-z_n| \leq (1+h \Lambda _{\phi_{f}})^{n} |y_0-z_0| \leq e^{hn \Lambda \phi_{f}} $$


    \end{exercise}


    \chapter{Tema 5}

    \section{Indicaciones sobre los métodos multipaso}

    Hay principalmente tres tipos de ejercicios en este tema:

    \begin{enumerate}
        \item Polinomio característico $ \rho(z) $ de segundo o tercer orden. Recordamos que $ \rho (1) = 0, \rho'(1) \ne 0 \implies \rho (z)= (z-1) \widetilde{\rho}(t)$. Normalmente hay un parámetro en los coeficientes de $ \rho(z) $, $ a $ y se piden condiciones sobre $ a $ para que se cumplan las condiciones de Dahlquist.
        \item Usar $ \rho(z) $ y $ \sigma (z) $ para determinar el orden del método. Recordemos que $ \ell(h) = C_0y(t) + C_1hy'(t) + C_2\dfrac{h^2}{2}y ^{(2)}(t) + C_3\dfrac{h^3}{3}y'''(t)+... $ y se tiene $ \ell(h) = O(h^2) \implies C_0 = C_1 = 0 $ ya que $ C_0 = \rho (1) = 0,\ C_1 = \rho'(1)-\sigma (1) = 0$ y $ C_{q} = \sum\limits_{j=0}^{k}j^{q}a_j - q \sum\limits_{j=0}^{k}j^{q-1}b_j $
        \item Usando fórmulas de interpolación determinar un método multipaso. Dado $ y_0,y_1,y_2 $ obtener $ \ell(s) $ usando $ L'(t)= hf(t_n,y_n) $.
    \end{enumerate}

    \section{Ejercicios}

    \begin{exercise}
        $$ y_{n+2}-y_{n+1} = \dfrac{h}{12}(4f_{n+2}+8f_{n+1}f_n) $$
        Aplicarlo a:
        $$ 
        \left\{
        \begin{array}{l}
            y'(t) = t = f(t,y)\\
            y(0) = 0
        \end{array}
        \right. $$
        (la solución es $ y(t) = \dfrac{t^2}{2} $)

        Al aplicar el esquema obtenemos:
        $$ y_{n+2}-y_{n+1} = \dfrac{h}{12}(4t_{n+2}+8t_{n+1}-t_n) $$
        
        Como $ t_n = nh $:
        $$ y_{n+2} = y_{n+1} = \dfrac{h}{12}(4(n+2)h+8h(n+1)-hn) = \dfrac{h^2}{12}(4n+8+8n+8-n) = $$
        $$ =\dfrac{h^2}{12}(11n+16) $$

        Tratamos de obtener la ecuación en diferencias:
        $$ y_{n+2}-y_{n+1} = \dfrac{h^2}{12}(11n+16) $$

        $$ n=0 \hspace{5mm} y_2-y_1 = \dfrac{h^2}{12}(11\cdot 0+16) $$
        $$ n=1 \hspace{5mm} y_3-y_2 = \dfrac{h^2}{12}(11\cdot 1+16) $$
        $$ n=1 \hspace{5mm} y_4-y_3 = \dfrac{h^2}{12}(11\cdot 2+16) $$

        $$ \sum\limits_{n=0}^{N-2}(y_{n+2}-y_{n+1}) = \sum\limits_{n=0}^{N-2}\dfrac{h^2}{12}(11 n +16) $$
        $$ y_{N}-y_1 = \dfrac{h^2}{12} \left( 11 \sum\limits_{n=0}^{N-2} n+16(N-1) \right) $$
        $$ y_{N} -y_1 = \dfrac{h^2}{12} \left( 11 \dfrac{(N-2)(N-1)}{2}+16N-16 \right) $$
        $$ y_{N} = y_1+\dfrac{h^2}{24} (11N^2-33N+22+32N-32) = y_1+\dfrac{h^2}{24}(11N^2-N-10) $$

        La solución exacta es $ y(t) = \dfrac{t^2}{2} $ entonces $ y(t_{N}) = \dfrac{N^2h^2}{2} $. Siempre comparamos $ y_n  $ con $ y(t_n) $. Siendo $ y_n $ la aproximación en $ t_n $:
        $$ E(t_N) = y(t_{N})-y_{N} = \dfrac{N^2h^2}{2}- \dfrac{11}{24}h^2N^2 + \dfrac{1}{24}h^2N^2-\dfrac{h^2}{12} $$
        
        En el límite estacionario:
        $$ \lim_{N \to \infty\ h \to 0\ Nh=tN} E(t_{N}) = \dfrac{t_{N}^2}{2} - \dfrac{11}{24}t_{N}^2 + \underbrace{\dfrac{1}{24}ht_{N} -\dfrac{h^2}{12}}_{ \to 0} = \dfrac{1}{24}t_{N}^2 \ne 0 $$

        Entonces $ y_{N} = \dfrac{11}{24}h^2N^2 - \dfrac{h^2N^2}{24}+\dfrac{h^2}{12} $ converge en el límite estacionario pero no a la solución exacta. $ y_N $ converge a $ z(t) \ne y(t) = \dfrac{t^2}{2} $.

        ¿Qué le sucede al esquema numérico para que haga esto?

        $$ y_{n+2}-y_{n+1} = \dfrac{h}{12}(4f_{n+2}+8f_{n+1}-f_n) $$

        Método de 2 pasos. Hace falta conocer $ y_0,y_1 $ para obtener $ y_2 $. Es un método de dos pasos \textbf{implícito} (para calcular $ y_2 $ usamos $ f_{2} $). Los polinomios son:
        $$ \rho(z) = z^2-z \hspace{5mm} \sigma(z) = \dfrac{1}{12}(4z^2+8z-1) $$

        Se cumple la condición de estabilidad ($ \rho(1)=0,\ \rho'(1) \ne 0 $). Se debe cumplir que $ \sigma(1) = \rho'(1) $ para la consistencia:
        $$ \sigma(1)=\dfrac{1}{12}(4+8-1) = \dfrac{11}{12} \ne \rho'(1) = 1 $$.
        
        Por tanto, el método no es consistente.

        Una forma de solucionar esto es cambiando el 12 del denominador por un 11.


        \begin{flushright}
            \textbf{Comentario extra}
        \end{flushright}

        En el cálculo de $ y_{N} $ hemos usado una suma telescópica. Esto es algo que en principio no lo vamos a poder usar en cualquier problema, vamos a usar otro método más general ahora:

        $$ y_{n+2}-y_{n+1} = \dfrac{h^2}{12}(1(n+2)+8(n+1)-n) = \dfrac{h^2}{12}(11n+16) $$

        Hacemos $ y_n = An^2+Bn $ para buscar una solución particular del problema no homogéneo.

        \textbf{Nota:} en el caso de tener el problema $ y_{n+2}-y_{n+1} = 0 $, tendríamos $ y_n = A 0^{n}+B 1^{n} $ para que el método tenga sentido obviamente necesitamos $ y_0=y_1=B $ y tendremos $ y_n = B $

        Volviendo al no homogéneo:
        $$ y_{n+2}-y_{n+1} = A(n+2)^2+B(n+2) - A(n+1)^2-B(n+1) =$$
        $$ =  An^2 + 2An +4A +Bn +2B - A n^2-2An-A-Bn-B= 2An +3A+B $$

        Entonces tendremos:
        $$ 2An+3A+B=\dfrac{h^2}{12}(11n+16) = \dfrac{11}{12}h^2n +\dfrac{16}{12}h^2 \implies $$
        $$ A = 11 \dfrac{h^2}{24}\hspace{5mm} B = \dfrac{16h^2}{12}-\dfrac{33}{24}h^2 = -\dfrac{1}{24}h^2 $$

        Con lo que llegamos a:
        $$ y_n ^{(P)} = \dfrac{11}{24}h^2n^2 - \dfrac{1}{24}h^2n $$
        
        A lo que tenemos que sumar aún la parte homogénea, hemos llegado a la solución particular para el no homogéneo solamente.
        $$ y_1 ^{(P)} = \dfrac{11}{24}h^2-\dfrac{1}{24}h^2 = \dfrac{10}{24}h^2 \ne y_1 = \dfrac{h^2}{2} $$
        
        La solución de la homogénea es $ y_n ^{(H)} = \dfrac{h^2}{2} $

        La solución general es entonces la suma de ambas partes:
        $$ y_n = y_n ^{(P)} y_n ^{(H)} = \dfrac{11}{24}h^2n^2-\dfrac{1}{24}h^2n + \dfrac{h^2}{2} $$
    \end{exercise}

    \setcounter{ex}{4}

    \begin{exercise}
        $$ y_{n+2}-(1+a)y_{n+1}+ay_n = h(\beta_1f_{n+1}+\beta_0f_n)  $$
        
        En este caso tenemos un método de dos pasos explícito, necesitamos $ y_0,y_1 $. Vamos a ver las condiciones para la convergencia.
        $$ \rho(z)=z^2-(1+a)z+a \hspace{5mm} \sigma(z) = \beta_1z+\beta_0$$

        0-estabilidad: $ \rho(1)=1-(1+a)+a=0,\ \rho(z)=(z-1)(z-a) $. Las raíces de $\rho$ son 0 y $ a $. Necesitamos por tanto que $ |a| <1 $ o bien $ |a|=1 $ con $ a\ne1 $ ya que la multiplicad de $ a $ ha de ser 1.

        Valores posibles de $ a $:
        $$ a=\left\{
        \begin{array}{l}
            -1 \\
            e^{i \theta} \ne 1
        \end{array}
        \right. $$

        También necesitamos
        $$ \rho'(z) = 2z - (1+a) \implies \rho'(1) = 1-a \ne 0 \implies a \ne 1 $$
        
        Consistencia:
        $$ \sigma(1) = \rho'(1) \iff \beta_1+\beta_0 = 1-a $$

        Recordemos que:
        $$ \ell(t;h) = C_0y(t)+C_1 h y'(t) + C_2 \dfrac{h^2}{2}y''(t) + C_3 \dfrac{h^3}{3!}y ^{(3)}(t) + ... $$

        Como $ C_0 = 0\ $ $C_1 = 0$, el error $ \ell(t;h) = O(h^2)\ \forall y$

        Comprobemos cuando es el método de orden 2 ($ C_2=0 $):
        $$ C_2 = \sum\limits_{j=0}^{2}(j^2a_j-2jb_j) = -(1+a)+4 -2 \beta_1 = 3-a+2beta_1 = 0 $$

        Para el caso de un orden del error local con orden 4 (o orden del método 3) necesitamos:
        $$ C_3 = 0 \iff \sum\limits_{j=0}^{3}(j^3a_j-3^2b_j)=7-a-3beta_1=0 $$

        Con las hipótesis que tenemos llegamos a 
        $$ \left\{
        \begin{array}{l}
            \beta_0 =2        \\
            \beta_1=4\\
            a=-5
        \end{array}
        \right. $$

        Pero en este caso perderemos la 0-estabilidad.

    \end{exercise}

    \setcounter{ex}{7}

    \begin{exercise}
       $$  y_{n+2} + (\alpha -1)y_{n+1} - \alpha y_n = \dfrac{h}{4}((\alpha+3)f_{n+2}+(3 \alpha +1 )f_n) $$
       $$ \rho(z) = z^2+(\alpha -1 )z -\alpha \hspace{5mm} \sigma(z) = (\alpha +3)\dfrac{z^2}{4} + 0\cdot z + (3 \alpha +1 ) $$

       Sabemos para garantizar la convergencia de al menos orden 1:
       \begin{itemize}
           \item $ \rho(1) = 0 $
           \item $ 0 \ne \rho'(1) = \sigma(1) $
       \end{itemize}

       $$ \ell(t;h) = c_0y(t)+c_1hy'(t)+c_2\dfrac{h^2}{2} y''(t) + c_3 \dfrac{h^3}{3!}y'''(t) $$

       $$ \left\{
       \begin{array}{l}
           c_0 = \rho(1)\\
           c_1 = \rho'(1)-\sigma(1)\\
           c_2 = \sum\limits_{j=0}^{2}j ^2 a_j - 2 \sum\limits_{j=0}^{2}jb_j
       \end{array}
       \right. $$

       Como tenemos:
       $$ \left\{
       \begin{array}{l}
           a_2 = 1\\
           a_1 = \alpha-1 \\
           a_0 = \alpha \\
           b_2 = (\alpha +3)\\
           b_1 = 0 \\
           b_0 = 3 \alpha +1 
       \end{array}
       \right. $$

       Podemos comprobar que 
       $$ \left\{
       \begin{array}{lr}
           c_0 = \rho(1) = 1 +(\alpha-1)1 - \alpha  = 0\\ 
           c_1 = \rho(1)-\sigma(1) = \alpha+1- \dfrac{4(\alpha +1)}{4} = 0 &  \\
           c_2 = \sum\limits_{j=0}^{2}j^2a_j -2 \sum\limits_{j=0}^{2}jb_j = \alpha-1+4-4 \dfrac{\alpha+3}{4} = \alpha +3 - (\alpha +3) = 0 & \\
           c_3 = \sum\limits_{j=0}^{2}j^3a_j - 3 \sum\limits_{j=0}^{2}j^2b_j = 8+ \alpha -1 -12 \dfrac{\alpha+3}{4} = 7+ \alpha -3 \alpha -9 = -2 \alpha -2 = 0 \iff \alpha = -1
       \end{array}
       \right. $$

       Entonces si $ \alpha \ne -1 \implies c_3 \ne 0 \implies \ell(h) = O(h^3)  \implies $ el error del método es de orden 2. Y si $ \alpha = -1 \implies c_3 = 0 \implies \ell(h) = O(h^{4}) $ al menos y el error del método sería de orden 3 al menos.
       
       Para comprobar que efectivamente el método es de orden 3 para $ \alpha = -1 $ calculamos $ c_4 $ y comprobamos que es distinto de 0:
       $$ c_4 = \sum\limits_{j=0}^{2}j^{4}-4 \sum\limits_{j=0}^{2}j^3b_j = -2+16 -4(8\cdot \dfrac{2}{4}) = -2 \ne 0 $$
 
       Para el caso de $ \alpha = -1 $ con $ y' = 0 = f(t,y(t)) $ el método es:
       
       $$ y_{n+2} = -2y_{n+1} + y_n = 0 $$

       Con $ y_0=0,\ y_1 = h,\ y_{n+2}-2y_{n+1}+y_n = 0 $ tomamos $ y_n = r^{n} \to r^{n+2}-2r^{n+1}+r^{n} = 0 \implies r^2 -2r +1 = 0 \iff (r-1)^2 = 0 \to r_1 = 1$ raíz doble. Entonces:
       $$ y_n = r_1^{n}(An+B) \text{ con $ A,B $ por determinar} \implies y_n = An+B$$
       Y tomando los valores iniciales llegamos a:
       $$ \left\{
       \begin{array}{l}
           y_0= 0 \to B = 0\\
           y_1 = h \to A = h
       \end{array}
       \right. $$

       Sin embargo, el problema $ y'(t) = 0, y(0) = 0 $ tiene solución $ y(t) = 0 $, lo que difiere con nuestros cálculos. ¿A qué se debe esto?

       El esquema $ y_{n+2}-y_{n+1}+y_n = 0 $ tiene como raíces de $ \rho(z)=z^2-2z+1 $, $ z = 1 $ doble. Por tanto el esquema no es estable.

       Dados $ y_0,y_1,\ y_n = An+B \implies B = y_0,\ A =y_1-y_0$ y el esquema será $ y_n = (y_1-y_0)n +y_0$. La convergencia implica que $ h \to 0 \implies t_1 \to t_0$ que son fijos (y a su vez esto implica que $ y^{h}_1 \to y_0^{h}$)

       Como en nuestro caso $ y_0 = 0,\ y_1 = h $ tenemos que $ y_1-y_0 = h \implies y_n = nh \to  $ No hay convergencia.

       Tendríamos que tomar $ y_1 = h \phi(h) $ con $ \phi(h) \to 0 $ tal que $ y_1-y_0 = t_n \phi(h) \to 0 $.

       Todo esto se debe a que $ r_1 = 1 $ es raíz doble y por tanto no se cumple la condición de Dahlquist.
    \end{exercise}



\end{document}
