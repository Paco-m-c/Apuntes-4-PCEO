\documentclass[openany]{book}
\usepackage[utf8]{inputenc}
\usepackage{verbatim}
\usepackage[hypertexnames=false]{hyperref}
\usepackage{amstext} 
\usepackage{array}   
\newcolumntype{C}{>{$}c<{$}} 


\input{structure}
\usepackage{geometry}
\geometry{
    top=3cm,
    bottom=3cm,
    left=3cm,
    right=3cm,
    headheight=14pt, 
    footskip=1.4cm,
    headsep=10pt,
}
\usepackage{graphicx}
\title{Ejercicios MNED}
\author{Paco Mora Caselles}
\date{\today}

\begin{document}

    \maketitle
    \chapter{Tema 1}


    \begin{exercise}
        $$ A_1 = \begin{pmatrix} 0.5 & 1 \\ -1 & 0.5 \end{pmatrix} \to \sigma(A) = \{0.5+i,0.5-i\} $$
        $ x,y $ son combinaciones lineales de $ e^{(0.5\pm i)t} $ es decir de $ \{e^{0.5t}e^{i},e^{0.5}e^{-i}\} $
    \end{exercise}

    \setcounter{ex}{4}
    \begin{exercise}
        $$ 
        \left\{
        \begin{array}{l}
            x'''(t) = \cos(x(t))+ \sin(x'(t)) - e^{x''(t)}+t^2\\
            x(0) = 3\\
            x'(0) = 7\\
            x''(0) = 13
        \end{array}
        \right.
        $$
        Consideramos 
        $$ 
        \left\{
        \begin{array}{l}
            x(t)\\
            u(t) = x'(t)\\
            v(t) = x''(t)
        \end{array}
        \right.
        $$
        Entonces la ecuación queda:
        $$ v'(t) = (x'''(t)) = (\cos(x(t)))+\sin(u(t))-e^{v(t)}+t^2 $$
        $$ \begin{pmatrix} x(t)\\u(t)\\v(t) \end{pmatrix} = \begin{pmatrix} 3 \\ 7 \\13 \end{pmatrix}  $$
        En versión matricial:
        $$ X(t) = \begin{pmatrix} x(t)\\u(t)\\v(t) \end{pmatrix}  $$
        $$ \dfrac{d}{dt} X(t) = F(t,X(t)) = \begin{pmatrix} u \\ v \\ \cos(x)+\sin(u)-e^{v}+t^2 \end{pmatrix}  $$
    \end{exercise}

    \setcounter{ex}{8}

    \begin{exercise}
        $$ e^{at}(y'+ay) = e^{at}y' + ae^{at}y = \dfrac{d}{/dt}(e^{at}y(t)) $$
        $$ e^{\int_{0}^{t}a(s)ds}\left(y'(t)-a(t)y(t)) = e^{\int_{0}^{t}a(s)ds}  y'(t)+a(t)e^{\int_{0}^{t}a(s)ds}y(t) \right) \dfrac{d}{dt}(e^{\int_{0}^{t}a(s)ds}y(t)) $$
        $$ \int_{0}^{t}\dfrac{d}{dt}(e^{at}y(t)) = e^{at}y(t)|_{t=0} ^{(t = t)} $$
        $$ \dfrac{d}{dt}(e^{at}y(t)) = d e^{at-bt} $$
        % No entiendo ni media de esto
    \end{exercise}

    \chapter{Tema 2}

    

    \setcounter{ex}{7}
    \begin{exercise}
        % \textbf{Ejercicio 8}\\
        a)
        $$ y_n = \dfrac{1-h}{1+(n-1)h}\ n = 0,..,N = \dfrac{1}{h}$$
        b)\\
        Utilizando que es una ecuación de variables separables, llegamos a:
        $$ y(t) = \dfrac{1}{1+t}  $$
        %no se que hace yo copio
        Dado $ t_{*}= nh  $ fijo, calculamos el límite estacionario:
        $$ \lim_{h \to 0\ n\to +\infty\ hn = t_{*}}y_{n}^{h}  = \lim \dfrac{1-h}{1+nh-h} = \lim \dfrac{1-h}{1+t_{*}-h} = \dfrac{1}{1+t_{*}} = y(t_{*})$$
        Es decir la solución exacta que hemos calculado.\\
        c)\\
        El resultado es:
        $$ y(t_{*})-y_{n}^h = \dfrac{-t_{*}h}{1+t_{*}^2+2t_{*}-h-ht_{*}} = O(h)_{h \to 0}$$
        con $ hn = t_{*} $.\\
        Que el error sea una $ O(h) $ significa que $ |y(t_{*}-y_{n}^h| \leq_{h\to 0} kh $
        Con $ k $ independiente de $ h $.\\
        Comprobaremos que el error sea una $ O(h) $:
        $$ |y(t_{*}-y_n^h| = h \dfrac{t_{*}}{|1+t_{*}^2+2t_{*}-h-ht_{*}|} $$
        Teniendo:
        $$ \dfrac{t_{*}}{1+t_{*}^2+2t_{*}-h-ht_{*}}\sim _{h\to 0} \dfrac{t_{*}}{1+t_{*}^2+2t_{*}} \leq \dfrac{1}{1} = 1 $$ 
        Luego el error lo podemos acotar por $ hk $ con $ k = 1 $ cuando $ h \to 0 $.\\
        
        Comprobaremos la optimalidad de esta cota.
        $$ y(t_{*})-y_{n}^h = \dfrac{-t_{*}h}{1+t_{*}^2+2t_{*}-h-ht_{*}} \leq ? k h^2 $$
        $$ \dfrac{1}{h^2} y(t_{*})-y_{n}^h = \dfrac{-t_{*}h}{1+t_{*}^2+2t_{*}-h-ht_{*}} \to_{h\to 0} \infty $$
        Luego el error es mayor o igual que $ h $ y menor que $ h^2 $.
        

    \end{exercise}
    

    \setcounter{ex}{5}
    \begin{exercise}
        $$ \left\{
        \begin{array}{l}
            y'(t) = t\\
            y(0) = 0
        \end{array}
        \right. $$
        Con solución exacta $ y(t) = \dfrac{t^2}{2} $
        El método de Euler explícito queda:
        $$ \left\{
        \begin{array}{l}
            y_0 = 0\\
            y_{n+1} = y_n + hf(t_n,g_n) = y_n +ht_n 
        \end{array}
        \right. $$

        Entonces:
        $$ y_0 =0\hspace{5mm}y_1 = y_0 +ht_0 = 0+0h = 0 $$
        $$ y_2 = 0 + hh = h^2\hspace{5mm}y_3 = h^2+2h^2 = 3h^2 $$
        $$ y_4 = (1+2+3) = 6h^2 \hspace{5mm} y_5 = (1+2+3+4)h^2 = 10h^2  $$
        En general:
        $$ y_n = (1+2+...+n-1)h^2  = \dfrac{(n-1)n}{2}h^2 = \dfrac{n^2-n}{2}h^2 = \dfrac{1}{2}n^2h^2-\dfrac{1}{2}nhh = \dfrac{1}{2}t_{*}^2-\dfrac{1}{2}t_{*}h \to \dfrac{1}{2}t_{*}^2$$
        Con lo que tenemos un error del orden de $ O(h) $
        
        \begin{flushright}
            \textbf{Variación del ejercicio}
        \end{flushright}
        $$ \left\{
        \begin{array}{l}
            y'(t) = 1\\
            y(0) = 0
        \end{array}
        \right. $$
        Con solución exacta $ y(t) = t $
        El método de Euler explícito queda:
        $$ \left\{
        \begin{array}{l}
            y_0 = 0\\
            y_{n+1} = y_n +h f(t_n,y_n) = y_n+h
        \end{array}
        \right. $$
        Con lo que:
        $$ y_0 = 0 \hspace{5mm} y_1 = h \hspace{5mm} y_2 = 2h\ ... $$
        $$ y_n = nh = t_{*} = y(t_{*}) $$
        Con lo que hemos obtenido la solución exacta, $ \forall t_{*} = nh\ y(t_{*}) - y_n^{h} = 0 $.
        ¿Por qué no hay error en el método de Euler en este caso? Porque la segunda derivada de la solución exacta, $ y'' \equiv 0 $ y porque hemos tomado un $ t_0 $ que forma parte de la solución.

        Si en vez de tomar 0 tomamos $ t_0 = \varepsilon $:
        $$ y_0 = \varepsilon \hspace{5mm} y_1 = \varepsilon +h \hspace{5mm} y_2 = \varepsilon +2h $$
        $$ y_n = \varepsilon +nh $$
        En este caso al no tomar un $ y_0  $ exacto el error se desvía por $ \varepsilon $

    \end{exercise}

    \setcounter{ex}{2}
    $$ (1+hL)^{n} \sim? e ^{Lt} $$
    con $ t = nh $
    O equivalentemente, que $ \lim_{t = nh} (1+hL)^{n} = e^{Lt}$
    $$ (1+hL)^{n} = e^{n \log(1+hL)} = e^{hn \dfrac{\log(1+hL)}{h}} \to e^{Lt} $$
    
    \textbf{c)}\\
    $$ (1+O(h^{p+1}))^{n} = exp(n \log(1+O(h ^{p+1}))) = exp(hn \dfrac{\log(1+O(h^{p+1}))}{n}) = e ^{t \dfrac{\log(1+O(h^{p+1}))}{n}} = ...$$
    Hacemos el desarrollo de Taylor en el exponente y nos queda $  = exp(t(O(h^{p})+...)) $
    
    \setcounter{ex}{9}
    
    \begin{exercise}
        Calculamos primero la solución exacta aunque no nos lo pida el ejercicio.
        $$ \left\{
        \begin{array}{l}
            y'(t) = \alpha y(t)+\beta\\
            y(0) = y_0
        \end{array}
        \right. $$
        $$ y' = -\alpha y = \beta $$
        $$ e^{-\alpha t}- \alpha e ^{-\alpha t} y = e ^{-\alpha t}y $$
        $$  \dfrac{d}{dt}(e^{-\alpha t }) y = e^{-\alpha t}\beta  $$
        $$ e^{-\alpha t}y -y_0 = \int_{0}^{t}e^{-\alpha s} \beta ds $$
        % $$ e^{-\alpha t}-y_0 = \dfrac{e^{-\alpha t}-1}{-\alpha}\beta $$
        $$ y(t) = e^{-\alpha t} y_0 - \dfrac{\beta}{\alpha}(1-e^{\alpha t}) $$
        Hacemos ahora Euler explícito:
        $$ \left\{
        \begin{array}{ll}
            u_{n+1} = y_n +h f(t_n,u_n) & n=0,...,\dfrac{N}{T}-1\\
            u_0 = A & \text{podemos asumir $ A = y_0 $}
        \end{array}
        \right. $$
        Recordemos que cada $ u_n $ es una aproximación a $ y(t_n) $.
        También podemos usar $ y_n $ como aproximación a $ y(t_n) $\\
        Es importante saber que $ y_n \ne y(t_n) $.\\
        En nuestro caso, $ f(t,y) = \alpha y +\beta $, luego $ u_{n+1} = u_n+h(\alpha y_n+\beta) $\\
        Tenemos entonces dos opciones:
        \begin{itemize}
            \item $ u_1=u_0+h(\alpha u_0+\beta) $\\
            $ u_2 =  u_1h \alpha( u_1+\beta) = u_1+h \alpha(u_0+h(\alpha u_0+\beta)+\beta) = $\\$ = u_1 + u_0 (h \alpha(h \alpha)^2+\beta (h^2alfa h \alpha)) = u_1 +h \alpha (1+h \alpha ) u_0+h \alpha (h+1) \beta$
            \item $ u_{n+1} = (1+h \alpha ) u_n+\beta h $, lo que nos queda:
                $ u_1 = (1+h \alpha ) u_0 + \beta h $\\ $ u_2 = (1+h \alpha )u_1+\beta h (1+h \alpha )u_0+ \beta h(1+(1+h \alpha))\\ u_3 = (1+h \alpha )u_2 + \beta h = (1+h \alpha) ((1+h \alpha)^2 u_0 + \beta h (1+(1+h \alpha))) + \beta h = (1+h \alpha) ^3 + \beta h(1(1+h \alpha )+ (1+h \alpha )^2) $\\
                $ u_n = (1+ h \alpha) ^{n} u_0 + \beta h (1+(1+h \alpha)+...+(1+h \alpha )^{n-1}) $\\
                $   = (1+h \alpha ) ^{n}u_0+ \dfrac{\beta}{\alpha}[(1+h \alpha )^{n}-1] $
        \end{itemize}
        
        Podemos observar que la convergencia del segundo método es mejor.

        Vamos a comprobar que $ u_n \to_{h \to 0,\ n \to +\infty,\ hn = t} y(t) $ cuando $ t = hn $ fijo.

        Sabemos que $ \lim_{x \to +\infty} \left(1+\dfrac{a}{x}\right) = e^{a} $. Entonces, $ (1+h \alpha)^{n} (1+\dfrac{h n}{n}\alpha) \to e ^{t \alpha}$, el valor que toma la solución exacta en el punto $ t_0 $.

        Calculemos ahora el error, sabemos que:
        $$ \int_{}^{} \dfrac{1}{1+x} = 1-x+x+x ^2-x^3 +... $$
        $$ \log{1+x} = x-\dfrac{x^2}{2} + \dfrac{x^3}{3}+... \hspace{5mm} \text{Desarrollo de Taylor de $ \log{1+x} $ alrededor de $ x=0 $ } $$
        
        El desarrollo de $ \dfrac{\log{(1+x)}}{x} = 1-\dfrac{x}{2}+O(x^2) $ con $ |x| \to 0 $

        Tomando entonces una $ x $ adecuada:

        $$ (1+h \alpha) ^{n} = e ^{n \log{(1+h \alpha)}} = e ^{n h \alpha \dfrac{\log{(1+h \alpha)}}{h \alpha}} = e ^{t \alpha (1- \dfrac{h \alpha}{2}+O(h^2))} = e ^{t \alpha }e^{-\dfrac{h \alpha ^2 t}{2}+ O(h^2)}$$

        Entonces, $ (1+h \alpha )^{n} = -e^{t \alpha} = e^{t \alpha} e^{...}-e^{t \alpha} = e^{t \alpha}(e ^{...}-1) = e ^{t \alpha }(... + \dfrac{[...]^2}{2!}+...) = $\\
        $ e ^{\alpha t} (-\dfrac{h \alpha ^2 t}{2}) + O(h^2) $

        Hemos llegado a:
        $$ (1+h \alpha) ^{n} - e^{t \alpha} = -\dfrac{h \alpha ^2 t}{2} e ^{\alpha t} + O(h ^2) $$
        
        Y el error es:
        $$ u_n-y_n = ((1+ h \alpha) ^{n}- e ^{ \alpha t})u_0 + \dfrac{\beta}{\alpha}((1+h \alpha)^{n}- e ^{\alpha t}) = -\dfrac{h \alpha ^2 t}{2}(u_0+ \dfrac{\beta}{\alpha}) e ^{\alpha t}+ O(h ^2)\hspace{5mm}h \to 0$$



        

    \end{exercise}

    \setcounter{ex}{11}

    \begin{exercise}
        Comprobamos el orden de Euler explícito del problema: 
        $$ y'(x) = \dfrac{1}{\sqrt{1-x}} \hspace{5mm} y(0) = 0 $$

        Observamos que la solución es $ y(x) = -\dfrac{(1-x)^{1/2}}{\dfrac{1}{2}} = 2 \sqrt{1-x} $

        Tenemos un problema en 1 ya que la derivada no está acotada en ese punto.

        % Observamos que $ f_{y} = 0  $ y $ f_{x} = \dfrac{1}{2}(1-x)^{-3/2} $, vamos a calcular los primeros términos de la recurrencia tomando $ x_n \in [0,1] $:

        % $$ y_1 = 0 + h(1-x_n)^{-\dfrac{1}{2}} = h$$
        % $$  y_2 = h+h(1-x_1)^{-\dfrac{1}{2}} $$
        
        Vemos la expresión del error local:
        $$ \ell(t;h) = \dfrac{h^2}{2} y''(t) $$
        $$ \ell(x;h) = \dfrac{h^2}{2} y''(x) $$
        
        Vemos que $ y''(x) = \dfrac{1}{2}(1-x)^{-3/2} $. En el caso de que $ x $ sea de la forma $ x = 1-h $ tendremos que $ \ell(1-h;h) = \dfrac{h^2}{4} \dfrac{1}{h^{3/2}} = \dfrac{1}{4} h ^{1/2}$
        Con lo que el error global no convergerá (tiene orden $ \dfrac{1}{2}-1 $).


    \end{exercise}

    \begin{exercise}
        $ n\geq N-1\\ 0 < \theta < 1,\ h=\dfrac{T}{N} $
        $$ \left\{
        \begin{array}{l}
            y_{n+1} = y_n+h f(t_n+ \theta h, y_n+ \theta f(t_n,y_n) )\\
            y_0\ dado
        \end{array}
        \right. $$

        Los pasos ahora son:
        \begin{enumerate}
            \item Obtenemos $ f(t_n,y_n) $
            \item Avanzamos desde $ (t_n,y_n) $ con pendiente $ f(t_n,y_n) $ hasta el punto $ t_{n+\theta} = t_n+ \theta h $ y obtenemos la abscisa $ y_{n+\theta} = y_n+\theta hf(t_n,y_n) $
            \item Sobre el punto $ (t_{n+\theta},y_{n+\theta}) $ obtenemos una nueva pendiente $ f(t_{n+\theta},y_{n+\theta}) $
            \item Aquí disponemos ya de dos pendientes, lo ideal es tomar $ k = b_1k_1+b_2k_2  $ con $ b_1+b_2 = 1 $ promedio y entonces avanzar desde $ t_n $ a $ t_{n+1} $ con esta pendiente:
                $$ y_{n+1} = y_n + hk \hspace{5mm} \text{con } k = b_1k_1+b_2+k_2 $$
            \item en el caso de este ejercicio es $ b_1 = 0,\ b_2 = 1 $ 


        \end{enumerate}
    
    \end{exercise}


    \setcounter{ex}{15}

    \begin{exercise}
        
    \end{exercise}


    \chapter{Tema 4}

    \setcounter{ex}{3}

    \begin{exercise}
        $$ 
        \begin{array}{c|ccc}
            0 & 0 & 0 & 0\\
            1 & 1 & 0 & 0\\
            1 & \dfrac{1}{2} & \dfrac{1}{2} & 0 \\\\
            \hline\\
            & \dfrac{3}{6} & \dfrac{1}{6} & \dfrac{2}{6}
        \end{array}
        $$

        Las condiciones para obtener un orden 3 son:
        \begin{enumerate}
            \item $ b_1+b_2+b_3 = 1 $ (lo tenemos) 
            \item $ b_2c_2+b_3c_3 = \dfrac{1}{2} $ (también se cumple)
            \item $ b_2+c_2^2+b_3c_3^2 = \dfrac{1}{3} $
        \end{enumerate}
        
        La última condición no se cumple, luego el método no es de orden $ 3 $, $ \ell(h) = O(h^{p+1}) $ para $ p \leq 2 $ (recordemos que el orden del error local es uno más que el método).

        Si usamos $ y'=y $ puede que la solución sea más precisa, pero esto no va a ocurrir en general. Con lo que no contradecimos con lo que hemos dicho para el orden del método:

        $$ f(t,y)=y \implies \left\{
        \begin{array}{l}
            k_1 = y_n\\
            k_2 = y_n+hy_n = (1+h)y_n\\
            k_3 = y_n + \dfrac{h}{2}(y_n+hy_n) = y_n+hy_n+\dfrac{h^2}{2}y_n = y_n\left(1+h+\dfrac{h^2}{2}\right)
        \end{array}
        \right.$$

        Entonces $ y_{n+1} = y_n+h \left( \dfrac{3}{6}y_n + \dfrac{1}{6}(1+h)y_n + \dfrac{2}{6}\left(1+h+\dfrac{h^2}{2}\right) y_n \right) = y_n \left( 1+h+\dfrac{h^2}{2}+\dfrac{h^3}{6} \right) $.

        Con lo que $ y_n = T_{3}(h)^{n} $ donde $ T_{3}(h) = 1+h+\dfrac{h^2}{2}+\dfrac{h^3}{3} $ y $ e^{h} = T_3(h) + O(h^{4}) $ y $ T_3(h) = e^{h}(1+O(h^{4})) $ Entonces:

        $$ T_{3}(h)^{n} =  e^{t_n} (1+O(h^{4}))^{n} = e^{t_n}(1+O(h^{3})) \implies y_n - e^{t_n} = O(h^3)$$

    \end{exercise}

    \setcounter{ex}{9}

    \begin{exercise}
        $$ y_{n+1} = y_n+h(\dfrac{1}{4}k_1+\dfrac{3}{4}k_2) $$
        Con:
        $$ \left\{
        \begin{array}{l}
            k_1 = f(t_n,y_n)\\
            k_2 = f(t+\dfrac{2}{3}h,y_n+\dfrac{2}{3}hf(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1))
        \end{array}
        \right. $$
        Podemos observar que la expresión anidada en $ k_2 $ parece una nueva $ k_i $, cambiamos nuestras $ k's $ para que el problema sea más intuitivo:
        $$ 
        \left\{
        \begin{array}{l}
            k_1 = f(t_n,y_n)\\
            k_2 = f(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1)\\
            k_3 = f(t_n+\dfrac{2}{3}h,y_n+\dfrac{2}{3}hk_2)\\
            y_{n+1} = y_n+h(\dfrac{1}{4}k_1+\dfrac{3}{4}k_3)
        \end{array}
        \right.
        $$

        \textbf{b)}

        El tablero de Butcher es:

        $$ 
        \begin{array}{c|ccc}
            0 & 0 & 0 & 0 \\
            \dfrac{1}{3} & \dfrac{1}{3} & 0 & 0\\ \\
            \dfrac{2}{3} & 0 & \dfrac{2}{3} & 0 \\ \\
            \hline \\
            & \dfrac{1}{4} & 0 & \dfrac{3}{4}

        \end{array}
        $$

        \textbf{c)}

        Comprobamos el orden:
        \begin{enumerate}
            \item $ b_1+b_2+b_3 = 1 $ (Se cumple)
            \item $ b_2c_2+b_3c_3 = \dfrac{1}{2} $ (Se cumple)
            \item $ b_2c_2^2+b_3c_3^2 = \dfrac{1}{3} $ (Se cumple)
            \item $ b_3c_2c_3 = \dfrac{1}{6} $ (Se cumple)
        \end{enumerate}

        Por tanto, el método es de orden máximo y en nuestro caso, es de orden 3.

        \textbf{a)}
        $$ y_{n+1} = y_n+h \Phi_{f}(t_n,y_n;h)\ \text{donde } \Phi_{f}(t_n,y_n;h) = \dfrac{1}{4}k_1+\dfrac{3}{4}k_3 $$
        $$ k_1 = f(t_n,y_n) \implies \text{$ k_1 $ es Lips con respecto al segundo argumento} $$
        $$ k_2 = f(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1) $$
        $$ k_2(y_n) = f(t_n+\dfrac{1}{3}h,y_n+\dfrac{1}{3}hk_1(y_n)) $$
        $$ k_2(z_n) = f(t_n+\dfrac{1}{3}h,z_n+\dfrac{1}{3}hk_1(z_n)) $$
        $$ |k_2(y_n)- k_2(z_n) | \leq L_{f}|y_n+\dfrac{1}{3}hk_1(y_n) - (z_n+\dfrac{1}{3}hk_1(z_n))| \leq L_{f}(|y_n-z_n|+\dfrac{1}{3}h(k_1(y_n)-k_1(z_n)))\leq$$
        $$ \leq L_{f}(|y_n-z_n| + \dfrac{1}{3}h |y_n-z_n|L_{f}) = (L_{f}+\dfrac{1}{3}hL_{f}^2) |y_n-z_n| = L_{f}' |y_n-z_n| $$

        $$ |k_3(y_n) - k_3(z_n)| \leq L_{f}(|y_n-z_n|  \dfrac{2}{3}h|k_2(y_n)-k_2(z_n)|) \leq L_{f}(1+\dfrac{2}{3}hL_{f}L_{f}') |y_n-z_n| $$

        En general:
        $$ y_{n+1} = y_n + h \Phi_{f}(t_n,y_n;h) $$
        $$ z_{n+1} = z_n + h \Phi_{f}(t_n,z_n;h) $$
        $$ |y_n-z_n| \leq (1+h \Lambda _{\Phi_{f}}) |y_n-z_n| $$
        con $ \Lambda_{f} = O(1) $ con lo que:
        $$ |y_n-z_n| \leq (1+h \Lambda _{\phi_{f}})^{n} |y_0-z_0| \leq e^{hn \Lambda \phi_{f}} $$


    \end{exercise}


    \chapter{Tema 5}

    \section{Indicaciones sobre los métodos multipaso}

    Hay principalmente tres tipos de ejercicios en este tema:

    \begin{enumerate}
        \item Polinomio característico $ \rho(z) $ de segundo o tercer orden. Recordamos que $ \rho (1) = 0, \rho'(1) \ne 0 \implies \rho (z)= (z-1) \widetilde{\rho}(t)$. Normalmente hay un parámetro en los coeficientes de $ \rho(z) $, $ a $ y se piden condiciones sobre $ a $ para que se cumplan las condiciones de Dalhquist.
        \item Usar $ \rho(z) $ y $ \sigma (z) $ para determinar el orden del método. Recordemos que $ \ell(h) = C_0y(t) + C_1hy'(t) + C_2\dfrac{h^2}{2}y ^{(2)}(t) + C_3\dfrac{h^3}{3}y'''(t)+... $ y se tiene $ \ell(h) = O(h^2) \implies C_0 = C_1 = 0 $ ya que $ C_0 = \rho (1) = 0,\ C_1 = \rho'(1)-\sigma (1) = 0$ y $ C_{q} = \sum\limits_{j=0}^{k}j^{q}a_j - q \sum\limits_{j=0}^{k}j^{q-1}b_j $
        \item Usando fórmulas de interpolación determinar un método multipaso. Dado $ y_0,y_1,y_2 $ obtener $ \ell(s) $ usando $ L'(t)= hf(t_n,y_n) $.
    \end{enumerate}

    \chapter{Anexo: otros ejercicios}




\end{document}
